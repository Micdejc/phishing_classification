{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f24c9c5-573a-42c1-b502-2be168f1241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing email 1/10...\n",
      "Processing email 2/10...\n",
      "Processing email 3/10...\n",
      "Processing email 4/10...\n",
      "Processing email 5/10...\n",
      "Processing email 6/10...\n",
      "Processing email 7/10...\n",
      "Processing email 8/10...\n",
      "Processing email 9/10...\n",
      "Processing email 10/10...\n",
      "✅ Classification complete! Results saved to emails_with_verdict.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "CSV_PATH = \"emails.csv\"                 # Input CSV file containing emails\n",
    "OUTPUT_PATH = \"emails_with_verdict.csv\" # Output CSV file with verdicts and justifications\n",
    "LM_STUDIO_API_URL = \"http://localhost:1234/v1/chat/completions\"  # LM Studio endpoint\n",
    "MODEL_NAME = \"llama-2-7b-chat\"          # Name of the Llama 2 model loaded in LM Studio\n",
    "\n",
    "# === HELPER FUNCTION ===\n",
    "def get_llama_analysis(email_text):\n",
    "    \"\"\"\n",
    "    Send an email text to Llama 2 via LM Studio to classify phishing.\n",
    "    \n",
    "    Returns a tuple:\n",
    "    - verdict: int (1 = phishing, 0 = not phishing)\n",
    "    - justification: str (brief explanation of the verdict)\n",
    "    \"\"\"\n",
    "    # Construct the prompt for the model\n",
    "    prompt = f\"\"\"\n",
    "    You are a cybersecurity expert specializing in phishing detection.\n",
    "    Analyze the following email and respond in **JSON** format with two fields:\n",
    "    - verdict: 1 for phishing, 0 for not phishing\n",
    "    - justification: a short explanation (1–3 sentences)\n",
    "    \n",
    "    Email content:\n",
    "    {email_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the payload for LM Studio API\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a cybersecurity assistant that outputs clear JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.0  # Makes the model deterministic (consistent output)\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Send POST request to LM Studio API\n",
    "        response = requests.post(LM_STUDIO_API_URL, json=payload)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        result = response.json()\n",
    "\n",
    "        # Extract the model's message content\n",
    "        content = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "        # Try to parse JSON response from the model\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            verdict = int(data.get(\"verdict\", 0))  # Default to 0 if missing\n",
    "            justification = data.get(\"justification\", \"\").strip()\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback if the model does not return valid JSON\n",
    "            verdict = 1 if \"phish\" in content.lower() else 0\n",
    "            justification = content\n",
    "        \n",
    "        return verdict, justification\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully\n",
    "        print(f\"Error processing email: {e}\")\n",
    "        return None, \"Error during processing\"\n",
    "\n",
    "# === MAIN SCRIPT ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Load CSV file into pandas DataFrame\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    \n",
    "    # Check that the CSV contains the required 'text' column\n",
    "    if 'text' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'text' column.\")\n",
    "\n",
    "    verdicts = []        # List to store Llama verdicts\n",
    "    justifications = []  # List to store Llama justifications\n",
    "\n",
    "    # Loop over each email in the CSV\n",
    "    for i, email in enumerate(df['text']):\n",
    "        print(f\"Processing email {i+1}/{len(df)}...\")\n",
    "        verdict, justification = get_llama_analysis(email)  # Call helper function\n",
    "        verdicts.append(verdict)\n",
    "        justifications.append(justification)\n",
    "        time.sleep(0.5)  # Prevent overwhelming the API\n",
    "\n",
    "    # Add new columns to the DataFrame\n",
    "    df['LLM verdict'] = verdicts\n",
    "    df['LLM justification'] = justifications\n",
    "\n",
    "    # Save the results to a new CSV file\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "    print(f\"✅ Classification complete! Results saved to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53840c6c-b3c1-41e2-9489-29829d5b747f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
